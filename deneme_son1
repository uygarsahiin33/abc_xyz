# app_abc_xyz_sql.py
# -*- coding: utf-8 -*-
# Streamlit: Trino/Presto SQL -> ABCâ€“XYZ sÄ±nÄ±flamasÄ± (6 ay) + ayarlanabilir eÅŸikler + manuel Ã§arpan grid
import math
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px

# ==================== BaÄŸlantÄ± ====================
from whitelotus.utils import create_selfservis_connection
engine = create_selfservis_connection()

# ==================== Ayarlar ====================
st.set_page_config(page_title="ABCâ€“XYZ (SQL â€¢ 6 Ay)", layout="wide")
st.title("ðŸ“¦ ABCâ€“XYZ Analizi (SQL â€¢ Son 6 Ay)")
st.caption("Kaynak: v_daily_store_item_sale â€¢ Varyans gÃ¼nlÃ¼k satÄ±ÅŸlar Ã¼zerinden (0 satÄ±ÅŸlÄ± gÃ¼nler dahil).")

ABCXYZ_ORDER = ["AX","AY","AZ","BX","BY","BZ","CX","CY","CZ"]
DEFAULT_MULTIPLIER_GRID = {
    "AX": 1.88, "AY": 1.64, "AZ": 1.48,
    "BX": 1.34, "BY": 1.28, "BZ": 1.23,
    "CX": 1.13, "CY": 1.04, "CZ": 0.84,
}

REQUIRED_COLS = ["MaÄŸaza Kodu", "ÃœrÃ¼n Kodu", "Toplam SatÄ±ÅŸ (6 Ay)", "Varyans"]

# ==================== YardÄ±mcÄ±lar ====================
def to_numeric_strict(s: pd.Series) -> pd.Series:
    ser = s.astype(str).str.replace(",", ".", regex=False)
    return pd.to_numeric(ser, errors="coerce").fillna(0)

def _percent_rank(series: pd.Series, ascending: bool) -> pd.Series:
    n = series.shape[0]
    if n <= 1:
        return pd.Series(np.zeros(n), index=series.index, dtype=float)
    r = series.rank(method="average", ascending=ascending)
    return (r - 1) / (n - 1)

def group_percent_rank(df: pd.DataFrame, value_col: str, ascending: bool, group_cols: list[str] | None):
    if not group_cols:
        return _percent_rank(df[value_col], ascending=ascending)
    return df.groupby(group_cols, group_keys=False)[value_col]\
             .apply(lambda s: _percent_rank(s, ascending=ascending))

def classify_from_pr(pr: float, cut1=0.20, cut2=0.60, labels=("A","B","C")) -> str:
    if pr <= cut1:
        return labels[0]
    elif pr <= cut2:
        return labels[1]
    else:
        return labels[2]

# ==================== SQL Query (yalnÄ±zca gerekli alanlar) ====================
# DÃœZELTÄ°LDÄ°: -1 AY -> -6 AY
SQL_QUERY = """
WITH params AS (
  SELECT
    date_add('month', -6, current_date) AS start_date,
    current_date                        AS end_date
),
raw AS (
  SELECT
    CAST(date_of_transaction AS date) AS tx_date,
    store_number,
    item_number,
    SUM(quantity_sold) AS qty
  FROM selfservis_migros.v_daily_store_item_sale s
  JOIN params p
    ON CAST(date_of_transaction AS date) BETWEEN p.start_date AND p.end_date
  GROUP BY 1, 2, 3
),
pairs AS (
  SELECT DISTINCT store_number, item_number FROM raw
),
calendar AS (
  SELECT d AS tx_date
  FROM (
    SELECT sequence(p.start_date, p.end_date, interval '1' day) AS days
    FROM params p
  )
  CROSS JOIN UNNEST(days) AS u(d)
),
grid AS (
  SELECT c.tx_date, pr.store_number, pr.item_number
  FROM calendar c
  CROSS JOIN pairs pr
),
daily AS (
  SELECT
    g.store_number,
    g.item_number,
    g.tx_date,
    COALESCE(r.qty, 0) AS daily_qty
  FROM grid g
  LEFT JOIN raw r
    ON r.store_number = g.store_number
   AND r.item_number  = g.item_number
   AND r.tx_date      = g.tx_date
)
SELECT
  CAST(store_number AS varchar) AS "MaÄŸaza Kodu",
  CAST(item_number  AS varchar) AS "ÃœrÃ¼n Kodu",
  SUM(daily_qty)                AS "Toplam SatÄ±ÅŸ (6 Ay)",
  COALESCE(var_pop(daily_qty), 0) AS "Varyans"
FROM daily
GROUP BY 1, 2
"""

# ==================== Cache'li veri Ã§ekme ====================
@st.cache_data(ttl=15 * 60, show_spinner=False)
def load_data():
    df = pd.read_sql(SQL_QUERY, engine)
    # Tip temizliÄŸi
    df["Toplam SatÄ±ÅŸ (6 Ay)"] = to_numeric_strict(df["Toplam SatÄ±ÅŸ (6 Ay)"])
    df["Varyans"] = to_numeric_strict(df["Varyans"])
    return df

with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    scope_choice = st.radio(
        "YÃ¼zde dilimi kapsamÄ± (Scope)",
        ["Global (tÃ¼m maÄŸazalar birlikte)", "MaÄŸaza bazÄ±nda (her maÄŸaza kendi iÃ§inde)"],
        index=0
    )
    scope_key = "global" if scope_choice.startswith("Global") else "store"

    st.subheader("ABC EÅŸikleri")
    abc_top = st.number_input("A Ã¼st dilim (%)", min_value=5.0, max_value=50.0, value=20.0, step=1.0) / 100.0
    abc_mid = st.number_input("B Ã¼st dilim (%)", min_value=30.0, max_value=90.0, value=60.0, step=1.0) / 100.0

    st.subheader("XYZ EÅŸikleri")
    xyz_low = st.number_input("X alt dilim (%)", min_value=5.0, max_value=50.0, value=20.0, step=1.0) / 100.0
    xyz_mid = st.number_input("Y Ã¼st dilim (%)", min_value=30.0, max_value=90.0, value=60.0, step=1.0) / 100.0

    # YENÄ°: XYZ metrik seÃ§imi
    xyz_metric = st.radio(
        "XYZ metriÄŸi",
        ["CV (Ïƒ/Î¼) â€” Ã¶nerilir", "Varyans (ham)"],
        index=0,
        help="Varyans hacimle artar; CV (std/mean) hacim etkisini dengeler ve daha adil bir XYZ verir."
    )

    st.subheader("Z-Ã‡arpan Grid (AX..CZ)")
    grid_z = {}
    cols = st.columns(3)
    defaults = DEFAULT_MULTIPLIER_GRID
    for idx, a in enumerate(["A", "B", "C"]):
        with cols[idx]:
            st.markdown(f"**{a} sÄ±nÄ±fÄ±**")
            for x in ["X", "Y", "Z"]:
                key = a + x
                grid_z[key] = st.number_input(
                    key, min_value=0.00, max_value=5.00, value=float(defaults[key]),
                    step=0.01, format="%.2f", key=f"z_{key}"
                )

    st.markdown("---")
    refresh = st.button("ðŸ”„ Veriyi Yenile")

# Veri Ã§ek
if refresh:
    load_data.clear()  # cache temizle
df = load_data()

# GiriÅŸ doÄŸrulamalarÄ±
missing = [c for c in REQUIRED_COLS if c not in df.columns]
if missing:
    st.error(f"Eksik kolonlar: {missing}")
    st.stop()

# MaÄŸaza filtresi
store_opts = ["(Hepsi)"] + sorted(df["MaÄŸaza Kodu"].dropna().astype(str).unique().tolist())
sel_store = st.selectbox("MaÄŸaza filtresi", store_opts, index=0)

df_work = df.copy()
if sel_store != "(Hepsi)":
    df_work = df_work[df_work["MaÄŸaza Kodu"].astype(str) == str(sel_store)]

st.success(f"Veri yÃ¼klendi: {len(df_work):,} satÄ±r (filtre: {sel_store})")

# ==================== ABCâ€“XYZ Hesaplama ====================
def compute_abc_xyz_base(
    df_in: pd.DataFrame,
    abc_top_cut: float,
    abc_mid_cut: float,
    xyz_low_cut: float,
    xyz_mid_cut: float,
    scope: str,
    zgrid: dict,
    xyz_metric_kind: str = "cv"  # "cv" veya "var"
):
    out = df_in.copy()
    out["Toplam SatÄ±ÅŸ (6 Ay)"] = to_numeric_strict(out["Toplam SatÄ±ÅŸ (6 Ay)"])
    out["Varyans"] = to_numeric_strict(out["Varyans"])

    # Scope -> group cols
    if scope == "global":
        group_cols = None
    elif scope == "store":
        group_cols = ["MaÄŸaza Kodu"]
    else:
        group_cols = None

    # ABC: satÄ±ÅŸ DESC
    pr_sales = group_percent_rank(out, "Toplam SatÄ±ÅŸ (6 Ay)", ascending=False, group_cols=group_cols)
    ABC = pr_sales.apply(lambda v: classify_from_pr(v, abc_top_cut, abc_mid_cut, ("A", "B", "C")))

    # XYZ: varyans ASC (tercihen CV ile)
    if xyz_metric_kind == "cv":
        # 6 aylÄ±k yaklaÅŸÄ±k gÃ¼n sayÄ±sÄ± (tÃ¼m kayÄ±tlar iÃ§in aynÄ±)
        today = pd.Timestamp.today().normalize()
        start = (today - pd.DateOffset(months=6)).normalize()
        ndays = max((today - start).days + 1, 1)
        mean_daily = out["Toplam SatÄ±ÅŸ (6 Ay)"] / ndays
        std_daily = np.sqrt(out["Varyans"])
        metric = std_daily / mean_daily.replace(0, np.nan)
        metric = metric.replace([np.inf, -np.inf], np.nan).fillna(metric.max(skipna=True) or 0)
        out["_xyz_metric_"] = metric
        pr_var = group_percent_rank(out, "_xyz_metric_", ascending=True, group_cols=group_cols)
    else:
        pr_var = group_percent_rank(out, "Varyans", ascending=True, group_cols=group_cols)

    XYZ = pr_var.apply(lambda v: classify_from_pr(v, xyz_low_cut, xyz_mid_cut, ("X", "Y", "Z")))
    out["ABC-XYZ Sonucu"] = (ABC + XYZ).astype(str)
    out["ABC-XYZ'e gÃ¶re Ã§arpan"] = out["ABC-XYZ Sonucu"].map(zgrid).fillna(1.0).astype(float).round(2)
    return out

out = compute_abc_xyz_base(
    df_work,
    abc_top_cut=abc_top, abc_mid_cut=abc_mid,
    xyz_low_cut=xyz_low, xyz_mid_cut=xyz_mid,
    scope=scope_key, zgrid=grid_z,
    xyz_metric_kind=("cv" if xyz_metric.startswith("CV") else "var")
)

# ==================== GÃ¶rseller ve Tablo ====================
tab_charts, tab_table = st.tabs(["ðŸ“Š DaÄŸÄ±lÄ±m Grafikleri", "ðŸ”Ž SonuÃ§ Tablosu"])

with tab_charts:
    st.subheader("Genel ABC-XYZ daÄŸÄ±lÄ±mÄ±")
    vc_all = out["ABC-XYZ Sonucu"].astype(str).value_counts()
    df_all = pd.DataFrame({"ABCXYZ": ABCXYZ_ORDER})
    df_all["count"] = df_all["ABCXYZ"].map(vc_all).fillna(0).astype(int)

    fig_all = px.pie(
        df_all, names="ABCXYZ", values="count",
        category_orders={"ABCXYZ": ABCXYZ_ORDER},
        hole=0.35, title="SeÃ§ili filtre iÃ§in ABC-XYZ daÄŸÄ±lÄ±mÄ±"
    )
    fig_all.update_traces(textposition="inside", textinfo="percent+label")
    st.plotly_chart(fig_all, use_container_width=True)

    st.markdown("---")
    st.subheader("A / B / C iÃ§inde Xâ€“Yâ€“Z kÄ±rÄ±lÄ±mlarÄ±")
    colA, colB, colC = st.columns(3)

    def sub_pie(letter: str, order_list: list[str], col):
        sub = out[out["ABC-XYZ Sonucu"].str.startswith(letter)]
        vc = sub["ABC-XYZ Sonucu"].astype(str).value_counts()
        dfx = pd.DataFrame({"ABCXYZ": order_list})
        dfx["count"] = dfx["ABCXYZ"].map(vc).fillna(0).astype(int)
        fig = px.pie(
            dfx, names="ABCXYZ", values="count",
            category_orders={"ABCXYZ": order_list},
            hole=0.35, title=f"{letter} sÄ±nÄ±fÄ± iÃ§inde daÄŸÄ±lÄ±m"
        )
        fig.update_traces(textposition="inside", textinfo="percent+label")
        col.plotly_chart(fig, use_container_width=True)

    sub_pie("A", ["AX", "AY", "AZ"], colA)
    sub_pie("B", ["BX", "BY", "BZ"], colB)
    sub_pie("C", ["CX", "CY", "CZ"], colC)

with tab_table:
    st.subheader("SonuÃ§lar")
    # Kategori sÄ±rasÄ±
    cat_order = pd.api.types.CategoricalDtype(categories=ABCXYZ_ORDER, ordered=True)
    preview_df = out.copy()
    preview_df["ABC-XYZ Sonucu"] = preview_df["ABC-XYZ Sonucu"].astype(cat_order)

    show_cols = ["MaÄŸaza Kodu", "ÃœrÃ¼n Kodu", "Toplam SatÄ±ÅŸ (6 Ay)", "Varyans", "ABC-XYZ Sonucu", "ABC-XYZ'e gÃ¶re Ã§arpan"]
    sort_cols = ["ABC-XYZ Sonucu", "MaÄŸaza Kodu", "ÃœrÃ¼n Kodu"]
    preview_df = preview_df.sort_values(sort_cols, na_position="last")
    st.dataframe(preview_df[show_cols].head(200), use_container_width=True)
